# #!/bin/bash
# #SBATCH --output=logs/exp_a/%x_%j.log
# #SBATCH --partition=gpu_a100
# #SBATCH --nodes=1
# #SBATCH --ntasks=1
# #SBATCH --gpus=1
# #SBATCH --cpus-per-task=18
# #SBATCH --time=08:00:00

# module purge
# module load 2023
# module load Miniconda3/23.5.2-0

# eval "$(/sw/arch/RHEL8/EB_production/2023/software/Miniconda3/23.5.2-0/bin/conda shell.bash hook)"
# conda activate hbird

# # all classes: 7,8,19,46,57,60,70,99,100,113,125,126,152,166,196
# python python_scripts/exp_a.py \
#   --model_repo google/siglip-base-patch16-224 \
#   --model_name "" \
#   --num_workers 8 \
#   --batch_size 32 \
#   --input_size 224 \
#   --patch_size 16 \
#   --d_model 768 \
#   --nn_method faiss \
#   --n_neighbours 30 \
#   --augmentation_epoch 1 \
#   --dataset_name mvimgnet \
#   --data_dir datasets/split_angles_mvimagenet \

# # We do not use this model, we should use siglip2