#!/bin/bash
#SBATCH --job-name=eval_mvimgnet_tips
#SBATCH --output=logs/working_models/eval_mvimgnet_tips_%j.log
#SBATCH --error=logs/working_models/eval_mvimgnet_tips_%j.log
#SBATCH --partition=gpu_a100
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gpus=1
#SBATCH --cpus-per-task=8
#SBATCH --time=00:05:00

# ToDo: Remember to change the job name and output file names to match the parameters

echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"

module purge
module load 2023
module load Miniconda3/23.5.2-0

eval "$(/sw/arch/RHEL8/EB_production/2023/software/Miniconda3/23.5.2-0/bin/conda shell.bash hook)"
conda activate hbird

cd $HOME/open-hummingbird-eval

# Add TIPS to PYTHONPATH (this is needed for the TIPS model)
export PYTHONPATH=/gpfs/home4/scur0542:$PYTHONPATH
# Check if TIPS is accessible
python -c "from tips.pytorch import image_encoder; print('TIPS imported successfully')"

srun python python_scripts/run_eval.py \
  --model_repo tips-b14 \
  --model_name "" \
  --batch_size 64 \
  --input_size 504 \
  --patch_size 14 \
  --d_model 768 \
  --nn_method faiss \
  --n_neighbours 30 \
  --augmentation_epoch 1 \
  --dataset_name mvimgnet \
  --data_dir ./datasets/split_angles_mvimagenet \
  --train_bins 90 \
  --val_bins 0 \
  --num_workers 8

# Notes:
# - Input size should be 448 (model was trained on this resolution) if not interpolated.
#   We want to interpolate and use input_size=504 for consistency.
