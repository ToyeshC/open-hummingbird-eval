{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3179e9",
   "metadata": {},
   "source": [
    "# Create MVImgNet bins\n",
    "\n",
    "This notebook creates the bins for the MVImgNet dataset.\n",
    "\n",
    "### Running for different categories \n",
    "\n",
    "Only need to change CLASS_NUM variable.\n",
    "\n",
    "All categories we are using in mvimgnet:\n",
    "`100  113  125  126  152  166  19  196  23  46  57  60  7  70  8  99`\n",
    "\n",
    "So far we have done the following:\n",
    "`7`,`8`, `70`, `100`, `19`, `46`, || `57`, `60`, `99`, `113`, `125`, `126`, `152`, `166`, `196`\n",
    "\n",
    "Doesn't work for class `23` as it's biggest max angle = 84.257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8cce0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NUM = 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "919c5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\"input_path\": \"/home/scur0542/open-hummingbird-eval/datasets/mvimgnet/\",\n",
    "    \"output_path\": \"/home/scur0542/open-hummingbird-eval/datasets/split_angles_mvimagenet/\",\n",
    "    \"colmap_script\": \"/home/scur0542/open-hummingbird-eval/colmap/scripts/python\",\n",
    "    \"ANGLE_BINS\": [0, 15, 30, 45, 60, 75, 90],\n",
    "    \"class_mapping\": {23: \"Laptop\", 46: \"Bed\", 19: \"Microwave\", 99: \"Coat Rack\", 126: \"Sink\", 125: \"Toilet\", \n",
    "    8: \"Sofa\", 166: \"Broccoli\", 7: \"Stove\", 152: \"Strings\", 196: \"Durian\", 113: \"Ceiling Lamp\", 70: \"Toy Dragon\",\n",
    "    60: \"Toy Cow\", 100: \"Guitar Stand\", 57: \"Toy Cat\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7ac89",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4618558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image, display\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfba5abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 0 : (197, 197)\n",
      "correct : 197\n",
      "len 15 : (197, 197)\n",
      "correct : 197\n",
      "len 30 : (197, 197)\n",
      "correct : 197\n",
      "len 45 : (197, 197)\n",
      "correct : 197\n",
      "len 60 : (197, 197)\n",
      "correct : 197\n",
      "len 75 : (197, 197)\n",
      "correct : 197\n",
      "len 90 : (197, 197)\n",
      "correct : 197\n",
      "len 0 : (91, 91)\n",
      "correct : 91\n",
      "len 15 : (91, 91)\n",
      "correct : 91\n",
      "len 30 : (91, 91)\n",
      "correct : 91\n",
      "len 45 : (91, 91)\n",
      "correct : 91\n",
      "len 60 : (91, 91)\n",
      "correct : 91\n",
      "len 75 : (91, 91)\n",
      "correct : 91\n",
      "len 90 : (91, 91)\n",
      "correct : 91\n",
      "len 0 : (120, 120)\n",
      "correct : 120\n",
      "len 15 : (120, 120)\n",
      "correct : 120\n",
      "len 30 : (120, 120)\n",
      "correct : 120\n",
      "len 45 : (120, 120)\n",
      "correct : 120\n",
      "len 60 : (120, 120)\n",
      "correct : 120\n",
      "len 75 : (120, 120)\n",
      "correct : 120\n",
      "len 90 : (120, 120)\n",
      "correct : 120\n",
      "len 0 : (23, 23)\n",
      "correct : 23\n",
      "len 15 : (23, 23)\n",
      "correct : 23\n",
      "len 30 : (23, 23)\n",
      "correct : 23\n",
      "len 45 : (23, 23)\n",
      "correct : 23\n",
      "len 60 : (23, 23)\n",
      "correct : 23\n",
      "len 75 : (23, 23)\n",
      "correct : 23\n",
      "len 90 : (23, 23)\n",
      "correct : 23\n",
      "len 0 : (762, 762)\n",
      "correct : 762\n",
      "len 15 : (762, 762)\n",
      "correct : 762\n",
      "len 30 : (762, 762)\n",
      "correct : 762\n",
      "len 45 : (762, 762)\n",
      "correct : 762\n",
      "len 60 : (762, 762)\n",
      "correct : 762\n",
      "len 75 : (762, 762)\n",
      "correct : 762\n",
      "len 90 : (762, 762)\n",
      "correct : 762\n",
      "len 0 : (697, 697)\n",
      "correct : 697\n",
      "len 15 : (697, 697)\n",
      "correct : 697\n",
      "len 30 : (697, 697)\n",
      "correct : 697\n",
      "len 45 : (697, 697)\n",
      "correct : 697\n",
      "len 60 : (697, 697)\n",
      "correct : 697\n",
      "len 75 : (697, 697)\n",
      "correct : 697\n",
      "len 90 : (697, 697)\n",
      "correct : 697\n",
      "len 0 : (625, 625)\n",
      "correct : 625\n",
      "len 15 : (625, 625)\n",
      "correct : 625\n",
      "len 30 : (625, 625)\n",
      "correct : 625\n",
      "len 45 : (625, 625)\n",
      "correct : 625\n",
      "len 60 : (625, 625)\n",
      "correct : 625\n",
      "len 75 : (625, 625)\n",
      "correct : 625\n",
      "len 90 : (625, 625)\n",
      "correct : 625\n",
      "len 0 : (97, 97)\n",
      "correct : 97\n",
      "len 15 : (97, 97)\n",
      "correct : 97\n",
      "len 30 : (97, 97)\n",
      "correct : 97\n",
      "len 45 : (97, 97)\n",
      "correct : 97\n",
      "len 60 : (97, 97)\n",
      "correct : 97\n",
      "len 75 : (97, 97)\n",
      "correct : 97\n",
      "len 90 : (97, 97)\n",
      "correct : 97\n",
      "len 0 : (218, 218)\n",
      "correct : 218\n",
      "len 15 : (218, 218)\n",
      "correct : 218\n",
      "len 30 : (218, 218)\n",
      "correct : 218\n",
      "len 45 : (218, 218)\n",
      "correct : 218\n",
      "len 60 : (218, 218)\n",
      "correct : 218\n",
      "len 75 : (218, 218)\n",
      "correct : 218\n",
      "len 90 : (218, 218)\n",
      "correct : 218\n",
      "len 0 : (145, 145)\n",
      "correct : 145\n",
      "len 15 : (145, 145)\n",
      "correct : 145\n",
      "len 30 : (145, 145)\n",
      "correct : 145\n",
      "len 45 : (145, 145)\n",
      "correct : 145\n",
      "len 60 : (145, 145)\n",
      "correct : 145\n",
      "len 75 : (145, 145)\n",
      "correct : 145\n",
      "len 90 : (145, 145)\n",
      "correct : 145\n",
      "len 0 : (58, 58)\n",
      "correct : 58\n",
      "len 15 : (58, 58)\n",
      "correct : 58\n",
      "len 30 : (58, 58)\n",
      "correct : 58\n",
      "len 45 : (58, 58)\n",
      "correct : 58\n",
      "len 60 : (58, 58)\n",
      "correct : 58\n",
      "len 75 : (58, 58)\n",
      "correct : 58\n",
      "len 90 : (58, 58)\n",
      "correct : 58\n",
      "len 0 : (30, 30)\n",
      "correct : 30\n",
      "len 15 : (30, 30)\n",
      "correct : 30\n",
      "len 30 : (30, 30)\n",
      "correct : 30\n",
      "len 45 : (30, 30)\n",
      "correct : 30\n",
      "len 60 : (30, 30)\n",
      "correct : 30\n",
      "len 75 : (30, 30)\n",
      "correct : 30\n",
      "len 90 : (30, 30)\n",
      "correct : 30\n",
      "len 0 : (191, 191)\n",
      "correct : 191\n",
      "len 15 : (191, 191)\n",
      "correct : 191\n",
      "len 30 : (191, 191)\n",
      "correct : 191\n",
      "len 45 : (191, 191)\n",
      "correct : 191\n",
      "len 60 : (191, 191)\n",
      "correct : 191\n",
      "len 75 : (191, 191)\n",
      "correct : 191\n",
      "len 90 : (191, 191)\n",
      "correct : 191\n",
      "len 0 : (210, 210)\n",
      "correct : 210\n",
      "len 15 : (210, 210)\n",
      "correct : 210\n",
      "len 30 : (210, 210)\n",
      "correct : 210\n",
      "len 45 : (210, 210)\n",
      "correct : 210\n",
      "len 60 : (210, 210)\n",
      "correct : 210\n",
      "len 75 : (210, 210)\n",
      "correct : 210\n",
      "len 90 : (210, 210)\n",
      "correct : 210\n",
      "len 0 : (758, 758)\n",
      "correct : 758\n",
      "len 15 : (758, 758)\n",
      "correct : 758\n",
      "len 30 : (758, 758)\n",
      "correct : 758\n",
      "len 45 : (758, 758)\n",
      "correct : 758\n",
      "len 60 : (758, 758)\n",
      "correct : 758\n",
      "len 75 : (758, 758)\n",
      "correct : 758\n",
      "len 90 : (758, 758)\n",
      "correct : 758\n",
      "4222\n"
     ]
    }
   ],
   "source": [
    "# TEST function\n",
    "\n",
    "\n",
    "tot_sum = 0\n",
    "for j in [7, 8, 19, 46, 57, 60, 70, 99, 100, 113, 125, 126, 152, 166, 196]:\n",
    "#  60, 113, 152\n",
    "    for i in [0, 15, 30, 45, 60, 75, 90]:\n",
    "        dirs_mask = os.listdir(f'/home/scur0542/open-hummingbird-eval/datasets/split_angles_mvimagenet/{j}/{i}/mask')\n",
    "        dirs_img = os.listdir(f'/home/scur0542/open-hummingbird-eval/datasets/split_angles_mvimagenet/{j}/{i}/img')\n",
    "\n",
    "        print(f'len {i} : {len(dirs_mask), len(dirs_img)}'  )\n",
    "\n",
    "        tot = 0\n",
    "        for img, mask in zip(sorted(dirs_img), sorted(dirs_mask)):\n",
    "            \n",
    "            mask = mask[:-4]\n",
    "            if img == mask:\n",
    "                # print('corr ',mask, img)\n",
    "                tot += 1\n",
    "            else:\n",
    "                print(mask, img)\n",
    "        \n",
    "        print(f'correct : {tot}')\n",
    "    tot_sum += tot\n",
    "print(tot_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b64ac8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# path  = Path('datasets/split_angles_mvimagenet/57/0/img/2a01190a_001.jpg')\n",
    "\n",
    "# parent_folder = path.parent.parent.parent.name \n",
    "# # /home/scur0542/open-hummingbird-eval/datasets/split_angles_mvimagenet/70/0/img/0000a9b5_001.jpg\n",
    "# print(parent_folder == '70')\n",
    "# print(parent_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c12d9",
   "metadata": {},
   "source": [
    "### Obtain the read_write_model from python\n",
    "In the open-hummingbird-eval, go to colmap, there is a scripts folder with a python which contains read_write_model.py \n",
    "\n",
    "The following functions are needed: \n",
    "read_images_binary & qvec2rotmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d6ba4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(CONFIG[\"colmap_script\"])\n",
    "\n",
    "from read_write_model import read_images_binary, qvec2rotmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "79ea2fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_paths(CLASS_NUM, input_base, output_base):\n",
    "    image_path = input_base + 'images/'\n",
    "    mask_path = input_base + 'mask/'\n",
    "    class_image_folder = image_path + str(CLASS_NUM) + '/'\n",
    "    class_mask_folder = mask_path + str(CLASS_NUM) + '/'\n",
    "    output_folder = output_base + str(CLASS_NUM) + '/'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    return class_image_folder, class_mask_folder, output_folder\n",
    "\n",
    "# Creating per class the (img & mask) inputs path and the output folder\n",
    "class_image_folder_path, class_mask_folder_path, output_folder = setup_paths(CLASS_NUM, CONFIG[\"input_path\"], CONFIG[\"output_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6c68ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(class_image_folder_path, class_mask_folder_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1ac058f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outputs_path(class_number, output_path, angle_bin):\n",
    "    # Naming files that go in the output\n",
    "    TXT_PATH = output_path + str(class_number) + '.txt'\n",
    "    CSV_PATH = output_path + str(class_number) + '.csv'\n",
    "    JSON_PATH = output_path + str(class_number) + '.json'\n",
    "    # Create the angle folders (0-90) in the output folder\n",
    "    for i in angle_bin:\n",
    "        os.makedirs(output_path+str(i), exist_ok=True)\n",
    "        os.makedirs(output_path+str(i)+'/img', exist_ok=True)\n",
    "        os.makedirs(output_path+str(i)+'/mask', exist_ok=True)\n",
    "    return TXT_PATH, CSV_PATH, JSON_PATH\n",
    "\n",
    "TXT_NAME, CSV_NAME, JSON_NAME = create_outputs_path(CLASS_NUM, output_folder, CONFIG[\"ANGLE_BINS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "bf453b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(TXT_NAME, CSV_NAME, JSON_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9f0bb983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_angles(images):\n",
    "    sorted_images = sorted(images.items(), key=lambda item: int(item[1].name.split(\".\")[0]))\n",
    "    angles_list = [0]\n",
    "    for i in range(1, len(sorted_images)):\n",
    "        prev = sorted_images[0][0]\n",
    "        curr = sorted_images[i][0]\n",
    "\n",
    "        image1 = images[prev]\n",
    "        image2 = images[curr]\n",
    "\n",
    "        R1 = qvec2rotmat(image1.qvec)\n",
    "        R2 = qvec2rotmat(image2.qvec)\n",
    "\n",
    "        R_rel = R2 @ R1.T\n",
    "\n",
    "        angle_rad = np.arccos((np.trace(R_rel) - 1) / 2)\n",
    "        angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "        angles_list.append(round(angle_deg, 3))\n",
    "    return angles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "88245f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_steps(angles_list):\n",
    "    steps_list = []\n",
    "    for i in range(1, len(angles_list)):\n",
    "\n",
    "        prev_angle = angles_list[i-1]\n",
    "        curr_angle = angles_list[i]\n",
    "        steps_list.append(round(abs(prev_angle-curr_angle), 3))\n",
    "    return steps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4ae3a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files :  225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:21<00:00, 10.67it/s]\n"
     ]
    }
   ],
   "source": [
    "def compute_and_log_angles(path_class_img, csv_path, angle_func = compute_angles, step_func = compute_steps):\n",
    "    \"\"\"\n",
    "    Compute angles and steps from COLMAP extrinsics for each image folder,\n",
    "    write results to CSV, and return nested dictionary with computed values.\n",
    "\n",
    "    Args:\n",
    "        path_class_img (str): Path to class image folders.\n",
    "        csv_path (str): Output CSV path.\n",
    "        angle_func (function): Function to compute angles (e.g., compute_angles).\n",
    "        step_func (function): Function to compute steps (e.g., compute_steps).\n",
    "\n",
    "    Returns:\n",
    "        nested_dic (dict): nested dictionary with angles and steps per image folder.\n",
    "    \"\"\"\n",
    "    # Initialize nested dictionary\n",
    "    nested_dict = {}\n",
    "\n",
    "    # Write CSV headers\n",
    "    with open(csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Create the Column Headers for the CSV file\n",
    "        # NOTE: 3D_points is still unused but kept for compatibility\n",
    "        writer.writerow(['id_img', 'range', 'min_angle', 'min_idx', 'max_angle', 'max_idx', 'num_img', 'step_mean', 'step_std', 'min_step', 'max_step', '3D_points'])\n",
    "\n",
    "    # Calculate angles with Colmap extrinsics for each image subsequently\n",
    "    sorted_folder = sorted(os.listdir(path_class_img))\n",
    "    print(\"Total files : \", len(sorted_folder))\n",
    "\n",
    "    # Loop over image folders\n",
    "    for filename in tqdm(sorted_folder):\n",
    "        file_cl_image_folder_path = path_class_img + filename\n",
    "        folder_path = file_cl_image_folder_path + '/images/'\n",
    "\n",
    "        # Get image files\n",
    "        if not os.path.exists(folder_path):\n",
    "            # skip if no images folder\n",
    "            print(\"There is not a folder for images\")\n",
    "            continue\n",
    "\n",
    "        list_images = []\n",
    "        for f in os.listdir(folder_path):\n",
    "            image_name = folder_path + f\n",
    "            list_images.append(image_name)\n",
    "        x = np.sort(list_images)\n",
    "\n",
    "        if not list_images:\n",
    "            # skip if no images found\n",
    "            print(\"There are no images in this folder\")\n",
    "            continue\n",
    "\n",
    "        # Read COLMAP binary\n",
    "        bin2 = file_cl_image_folder_path +'/sparse/0/images.bin'\n",
    "        if not os.path.exists(bin2):\n",
    "            # skip sparse folder that don't have colmap stats\n",
    "            print(\"The sparse folder does not contain COLMAP statistics\")\n",
    "            continue\n",
    "        \n",
    "        images = read_images_binary(bin2)\n",
    "\n",
    "        # Compute angles & steps\n",
    "        angle_list = angle_func(images)\n",
    "        step_list = step_func(angle_list)\n",
    "\n",
    "        # Collect stats\n",
    "        min_angle = min(angle_list)\n",
    "        max_angle = max(angle_list)\n",
    "        idx_min_angle = np.argmin(angle_list)\n",
    "        idx_max_angle = np.argmax(angle_list)\n",
    "\n",
    "        dic = {\n",
    "            'angles': angle_list,\n",
    "            'step': step_list\n",
    "        }\n",
    "\n",
    "        nested_dict[filename] = dic\n",
    "\n",
    "        # Write per row in csv.file\n",
    "        with open(csv_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            step_mean = float(np.round(np.mean(step_list), 2))\n",
    "            step_std = float(np.round(np.std(step_list), 2))\n",
    "            min_step = float(np.round(np.min(step_list), 2))\n",
    "            max_step = float(np.round(np.max(step_list), 2))\n",
    "\n",
    "            writer.writerow([filename,\n",
    "                             abs(round(min_angle, 3) - round(max_angle, 3)),\n",
    "                             round(min_angle, 3), idx_min_angle,\n",
    "                             round(max_angle, 3), idx_max_angle,\n",
    "                             len(list_images),\n",
    "                             step_mean, step_std,\n",
    "                             min_step, max_step])  # Placeholder for 3D_points column if needed\n",
    "\n",
    "    return nested_dict\n",
    "\n",
    "\n",
    "nested_dic = compute_and_log_angles(class_image_folder_path, CSV_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c638f",
   "metadata": {},
   "source": [
    "### What is the stucture of the JSON file?\n",
    "\n",
    "```\n",
    "{\n",
    "  \"some_id\": {\n",
    "    \"angles\": [...],\n",
    "    \"step\": [...]\n",
    "  },\n",
    "  \"another_id\": {\n",
    "    \"angles\": [...],\n",
    "    \"step\": [...]\n",
    "  },\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "1. Keys (like \"00000b90\", \"00001d21\", etc.):\n",
    "    1. These are identifiers (likely strings from filenames, image IDs, sample IDs, etc.).\n",
    "    2. Every ID corresponds to one object/entity.\n",
    "2. Values (dictionaries with \"angles\" and \"step\"):\n",
    "    1. Each ID maps to a dictionary with:\n",
    "      1. \"angles\": A list of floats for the computed rotation angles of each image in that folder, relative to the first image (in degrees).\n",
    "      2. \"step\": A list of floats for the differences between consecutive angles (how much the view changed between each image).\n",
    "\n",
    "\n",
    "#### Example Entry:\n",
    "```\n",
    "\"00000b90\": {\n",
    "  \"angles\": [0, 3.831, 9.897, 15.838, ...],\n",
    "  \"step\": [3.831, 6.066, 5.941, 6.274, ...]\n",
    "},\n",
    "  \"00001d21\": {\n",
    "    \"angles\": [\n",
    "      0,\n",
    "      0.374,\n",
    "      1.748,\n",
    "      4.001, ...\n",
    "    ],\n",
    "    \"step\": [\n",
    "      0.374,\n",
    "      1.374,\n",
    "      2.253,\n",
    "      3.397, ...\n",
    "    ]\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2dd66e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the nested dictionary to a binary file\n",
    "with open(JSON_NAME, 'w') as file:\n",
    "    json.dump(nested_dic, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8ec36994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ids_by_angle(csv_name, txt_name, final_angle):\n",
    "    \"\"\"\n",
    "    Filters IDs from a CSV file where 'max_angle' >= final_angle\n",
    "    and appends them to a text file (one per line).\n",
    "\n",
    "    Parameters:\n",
    "    - csv_name (str): Path to the CSV file.\n",
    "    - txt_name (str): Path to the output TXT file.\n",
    "    - final_angle (float): Threshold to filter 'max_angle'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter angle range, then add the img_id to a txt file\n",
    "    df = pd.read_csv(csv_name)\n",
    "    ids_to_write = df[df['max_angle'] >= final_angle]['id_img']\n",
    "    \n",
    "    if ids_to_write.empty:\n",
    "        print(f'The biggest angle (= {max(df[\"max_angle\"])}) of this category ({CONFIG[\"class_mapping\"][CLASS_NUM]}) is smaller than the given final angle (= {final_angle})')\n",
    "        raise ValueError(f'No images found with angle greater or equal to {final_angle}. TXT file for {CONFIG[\"class_mapping\"][CLASS_NUM]} will be empty. TXT file not created.')\n",
    "        return\n",
    "\n",
    "    with open(txt_name, 'a') as f:\n",
    "        for idd in ids_to_write:\n",
    "            f.write(f\"{idd}\\n\")\n",
    "\n",
    "FINAL_ANGLE = CONFIG[\"ANGLE_BINS\"][-1]\n",
    "filter_ids_by_angle(CSV_NAME, TXT_NAME, FINAL_ANGLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c0e6c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_copy_images(class_image_folder_path, class_mask_folder_path, output_folder, json_name = JSON_NAME, txt_name = TXT_NAME, angle_bins = CONFIG[\"ANGLE_BINS\"]):\n",
    "    \"\"\"\n",
    "    Processes images and masks based on angle bins, copies them to new folders, \n",
    "    and computes error statistics.\n",
    "\n",
    "    Parameters:\n",
    "    - json_name (str): Path to the JSON file with angle information.\n",
    "    - txt_name (str): Path to the TXT file with selected image IDs.\n",
    "    - class_image_folder_path (str): Path to the image folders.\n",
    "    - class_mask_folder_path (str): Path to the mask folders.\n",
    "    - output_folder (str): Destination folder for processed images and masks.\n",
    "    - angle_bins (list): A list containing the desired bins for the angles (from CONFIG[\"ANGLE_BINS\"])\n",
    "\n",
    "    Returns:\n",
    "    - (float, float): Standard deviation and mean of angle errors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the nested dictionary from the previously created JSON file\n",
    "    with open(json_name, 'r') as f:\n",
    "        nested_dict = json.load(f)\n",
    "\n",
    "\n",
    "    if not os.path.exists(txt_name):\n",
    "        raise ValueError(f\"Warning: {txt_name} does not exist. Skipping processing. Please delete this category.\")\n",
    "        return\n",
    "\n",
    "    # Load names of image folders that have enough degrees\n",
    "    with open(txt_name, 'r') as f:\n",
    "        # Returns a list of strings\n",
    "        data = [line.strip() for line in f]\n",
    "    \n",
    "    if not data:\n",
    "        raise ValueError(\"Warning: No images found to process. TXT file is empty.\")\n",
    "        return\n",
    "\n",
    "    # Add the images and mask in the folders\n",
    "    tot_err = []\n",
    "\n",
    "    for img_folder in tqdm(data):\n",
    "        source_folder = class_image_folder_path + str(img_folder) +'/images/'\n",
    "        source_folder_2 = class_mask_folder_path + str(img_folder)\n",
    "\n",
    "        images = [f for f in sorted(os.listdir(source_folder)) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        images_2 = [f for f in sorted(os.listdir(source_folder_2)) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "        # skip when images or masks are missing in either lists\n",
    "        if len(images_2) != len(images):\n",
    "            continue\n",
    "\n",
    "        angles = nested_dict[img_folder]['angles']\n",
    "\n",
    "        i_want_angles = []\n",
    "        i_want_masks = []\n",
    "\n",
    "        for angle_bin in angle_bins:\n",
    "            closest = min(angles, key=lambda x: abs(x - angle_bin))\n",
    "            index = angles.index(closest)\n",
    "            tot_err.append(closest - angle_bin)\n",
    "\n",
    "            i_want_angles.append(images[index])\n",
    "            i_want_masks.append(images_2[index])\n",
    "\n",
    "        # Copy images to the corresponding folders\n",
    "        for i, img in enumerate(i_want_angles):\n",
    "            folder_img = output_folder + str(angle_bins[i]) + '/img'\n",
    "\n",
    "            src_path = os.path.join(source_folder, img)\n",
    "            dst_path = os.path.join(folder_img, f\"{img_folder}_{img}\")\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "        # Copy masks to the corresponding folders\n",
    "        for i, img in enumerate(i_want_masks):\n",
    "            folder_mask = output_folder + str(angle_bins[i]) + '/mask'\n",
    "            src_path = os.path.join(source_folder_2, img)\n",
    "            dst_path = os.path.join(folder_mask, f\"{img_folder}_{img}\")\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "    # IF ERROR std is smaller than 5 degrees\n",
    "\n",
    "    # Calculate the mean and standard deviation of the error\n",
    "    std_err = round(np.std(tot_err), 2)\n",
    "    mean_err = round(np.mean(tot_err), 2)\n",
    "\n",
    "    print(f\"std of error: {std_err}\\nmean of error: {mean_err}\")\n",
    "\n",
    "    return data, std_err, mean_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8f0d385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "627"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/scur0542/open-hummingbird-eval/datasets/split_angles_mvimagenet/70/70.txt', 'r') as f:\n",
    "    # Returns a list of strings\n",
    "    data = [line.strip() for line in f]\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "21e53763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:06<00:00, 31.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std of error: 1.24\n",
      "mean of error: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data, std, mean = process_and_copy_images(class_image_folder_path, class_mask_folder_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3d2166c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged errors for class 152 to global CSV and summary file.\n"
     ]
    }
   ],
   "source": [
    "def log_errors(mean_error, std_error, num_images_processed, class_num, class_cat, output_folder, csv_folder, global_log_csv='processing_log.csv'):\n",
    "    # Global CSV log entry\n",
    "    log_entry = {\n",
    "        'run_timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M\"),\n",
    "        'class_num': class_num,\n",
    "        'class_category' : class_cat,\n",
    "        'std_error': std_error,\n",
    "        'mean_error': mean_error,\n",
    "        'num_images_processed': num_images_processed\n",
    "    }\n",
    "\n",
    "    log_df = pd.DataFrame([log_entry])\n",
    "\n",
    "    # Append to global log CSV\n",
    "    path_log_csv = os.path.join(csv_folder, global_log_csv)\n",
    "    if os.path.exists(path_log_csv):\n",
    "        log_df.to_csv(path_log_csv, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        log_df.to_csv(path_log_csv, index=False)\n",
    "\n",
    "    # Local stats summary per class\n",
    "    summary_file = os.path.join(output_folder, 'stats_summary.txt')\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(f\"Class: {class_num}\\n\")\n",
    "        f.write(f\"Mean error: {mean_error:.2f} degrees\\n\")\n",
    "        f.write(f\"Std error: {std_error:.2f} degrees\\n\")\n",
    "        f.write(f\"num_images_processed: {num_images_processed} img\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    print(f'Logged errors for class {class_num} to global CSV and summary file.')\n",
    "\n",
    "# Usage example:\n",
    "log_errors(mean, std, len(data), CLASS_NUM, CONFIG[\"class_mapping\"][CLASS_NUM], output_folder, CONFIG[\"output_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c20c4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_angle_histogram(class_number, histogram_bins = 100):\n",
    "    output_path = CONFIG[\"output_path\"]\n",
    "    class_mapping = CONFIG[\"class_mapping\"]\n",
    "\n",
    "    if class_number not in class_mapping:\n",
    "        raise ValueError(f\"Class number {class_number} is not in the class mapping.\")\n",
    "\n",
    "    category = class_mapping[class_number]\n",
    "    output_folder = output_path + str(class_number) + '/'\n",
    "    csv_name = output_folder + str(class_number) + '.csv'\n",
    "\n",
    "    if not os.path.exists(csv_name):\n",
    "        raise FileNotFoundError(f\"CSV file not found: {csv_name}\")\n",
    "\n",
    "    df = pd.read_csv(csv_name)\n",
    "    print(f\"Loaded CSV with {df.shape[0]} rows.\")\n",
    "\n",
    "    if 'max_angle' not in df.columns:\n",
    "        raise ValueError(f\"'max_angle' column not found in {csv_name}\")\n",
    "\n",
    "    # Optional: Downsample if too large (e.g., > 100,000 rows)\n",
    "    if df.shape[0] > 100000:\n",
    "        df = df.sample(100000, random_state=42)\n",
    "        print(\"Data was downsampled to 100,000 rows for performance.\")\n",
    "\n",
    "    sns.histplot(df['max_angle'], bins= histogram_bins, kde=True, color='green', edgecolor='gray')\n",
    "\n",
    "    plt.xlabel('Angle in degrees')\n",
    "    plt.ylabel(f'Instances of class {class_number}: \\\"{category}\\\"')\n",
    "    plt.axvline(x=90, color='red', linestyle='--', label='90 degrees')\n",
    "    plt.legend()\n",
    "    plt.title(f'Class {class_number} \\\"{category}\\\": max angle histogram')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(output_folder, f\"{class_number}_angle_histogram.png\")\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"Plot saved as: {plot_filename}\")\n",
    "    plt.close()\n",
    "\n",
    "    return plot_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4d5053c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV with 225 rows.\n",
      "Plot saved as: /home/scur0542/open-hummingbird-eval/datasets/split_angles_mvimagenet/152/152_angle_histogram.png\n"
     ]
    }
   ],
   "source": [
    "# Create the histogram for the CLASS explored\n",
    "histogram_path = plot_class_angle_histogram(CLASS_NUM)\n",
    "# display(Image(filename=histogram_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd185835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
