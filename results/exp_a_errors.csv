e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x2e6d2550 size 53125054464 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='tips-b14', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=448, patch_size=14, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num='all', batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x295f2d70 size 39837499392 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='tips-b14', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=448, patch_size=14, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num='all', batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x2e0cb4c0 size 53049556992 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='google/siglip2-base-patch16-512', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num='all', batch_size=32, augmentation_epoch=1, memory_size=None, num_workers=8, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x2e0c2060 size 39762001920 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='google/siglip2-base-patch16-512', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num='all', batch_size=32, augmentation_epoch=1, memory_size=None, num_workers=8, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=OutOfMemoryError('CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 39.50 GiB of which 88.12 MiB is free. Including non-PyTorch memory, this process has 39.39 GiB memory in use. Of the allocated memory 12.10 GiB is allocated by PyTorch, and 618.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)'), args=Namespace(seed=42, model_repo='google/siglip2-base-patch16-512', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num='all', batch_size=32, augmentation_epoch=1, memory_size=None, num_workers=8, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x22cc86a0 size 53125054464 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='nvidia/C-RADIOv2-B', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x255d5430 size 53125054464 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='openai/clip-vit-base-patch16', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x2470d1a0 size 53125054464 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='facebookresearch/dino:main', model_name='dino_vitb16', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x2fce4270 size 53125054464 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='google/siglip2-base-patch16-512', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x22ce05c0 size 39837499392 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='nvidia/C-RADIOv2-B', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x66c6e450 size 39837499392 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='openai/clip-vit-base-patch16', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x2fce4270 size 39837499392 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='google/siglip2-base-patch16-512', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=RuntimeError("Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x238ff190 size 39837499392 bytes (cudaMalloc error out of memory [2])\n"), args=Namespace(seed=42, model_repo='facebookresearch/dino:main', model_name='dino_vitb16', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=OutOfMemoryError('CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 39.50 GiB of which 80.12 MiB is free. Including non-PyTorch memory, this process has 39.41 GiB memory in use. Of the allocated memory 12.42 GiB is allocated by PyTorch, and 222.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)'), args=Namespace(seed=42, model_repo='google/siglip2-base-patch16-512', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=OutOfMemoryError('CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 39.50 GiB of which 90.12 MiB is free. Including non-PyTorch memory, this process has 39.40 GiB memory in use. Of the allocated memory 12.17 GiB is allocated by PyTorch, and 471.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)'), args=Namespace(seed=42, model_repo='openai/clip-vit-base-patch16', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=OutOfMemoryError('CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 39.50 GiB of which 58.12 MiB is free. Including non-PyTorch memory, this process has 39.43 GiB memory in use. Of the allocated memory 12.23 GiB is allocated by PyTorch, and 447.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)'), args=Namespace(seed=42, model_repo='nvidia/C-RADIOv2-B', model_name='', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
e=OutOfMemoryError('CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacity of 39.50 GiB of which 64.12 MiB is free. Including non-PyTorch memory, this process has 39.42 GiB memory in use. Of the allocated memory 12.17 GiB is allocated by PyTorch, and 501.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)'), args=Namespace(seed=42, model_repo='facebookresearch/dino:main', model_name='dino_vitb16', d_model=768, hf_repo=None, hf_filename=None, input_size=512, patch_size=16, data_dir='datasets/split_angles_mvimagenet', dataset_name='mvimgnet', train_fs_path=None, val_fs_path=None, train_bins=None, val_bins=None, class_num=None, batch_size=8, augmentation_epoch=1, memory_size=None, num_workers=16, n_neighbours=30, nn_method='faiss', nn_params=None, return_knn_details=False, job_id=None)
